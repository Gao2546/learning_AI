version: '3.8'

services:

  api_server:
    build:
      context: .
      dockerfile: api_server/Dockerfile
    ports:
      - "5000:5000"
    environment:
      - PGDATABASE=ai_agent #<=========================================
      - PGUSER=athip
      - PGPASSWORD=123456
      - PGHOST=db
      - PGPORT=5432
      - IS_DOCKER=true
      # Pass the OpenAI API key from the host environment or a .env file
      # Ensure OPENAI_API_KEY is set in your environment before running docker-compose up
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all # Or specify a specific number of GPUs
    #           capabilities: [gpu]
    runtime: nvidia
    networks:
      - app-network

    # Deploy constraints to ensure 'api_server' runs on Host B
    # deploy:
    #   placement:
    #     constraints:
    #       - node.hostname == host_b_hostname # Replace with Host B's actual hostname
    #     resources: # If you need GPU resource reservation
    #       reservations:
    #         devices:
    #           - driver: nvidia
    #             count: all # Or specify a specific number of GPUs
    #             capabilities: [gpu]


  ollama:
    image: ollama/ollama
    # ports:
      # - "11434:11434"
    volumes:
      - /usr/share/ollama/.ollama:/root/.ollama
    networks:
      - app-network
    # Uncomment below if you want GPU access with NVIDIA
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    runtime: nvidia

    # Deploy constraints to ensure 'ollama' runs on Host B
    # deploy:
    #   placement:
    #     constraints:
    #       - node.hostname == host_b_hostname # Replace with Host B's actual hostname
    #     resources: # If you need GPU resource reservation
    #       reservations:
    #         devices:
    #           - driver: nvidia
    #             count: all
    #             capabilities: [gpu]

networks:
  app-network:
    # driver: bridge
    external:
      # name: my_shared_overlay_network # <--- Reference the external network
      name: my_simulation_network