{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978fbdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athip/psu/learning_AI/env/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import Embedding, Linear, Module, CrossEntropyLoss, BCELoss, MSELoss\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5742c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import BPEs, BPEsQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a337d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\", use_fast=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "encoding = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2e5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "def preprocess_data(data):\n",
    "    # Example preprocessing: lowercasing and stripping whitespace\n",
    "    data = data.split()\n",
    "    return [\" \".join(data[i:i + 100]) for i in range(0, len(data), 20)]\n",
    "def tokenize_data(data):\n",
    "    return tokenizer(data, padding=True, truncation=True,max_length=128, return_tensors=\"pt\")\n",
    "def encoding_data(data):\n",
    "    return encoding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143cce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/PythonCodeDataSmall_TextOnly/Python_code_data.txt\"\n",
    "path2 = \"./data/PythonCodeDataSmall_TextOnly/Python_code_data.txt\"\n",
    "# data = load_data(path)\n",
    "new_tokenizer = BPEsQA(vocab_size=1024*2)\n",
    "# new_tokenizer.train([path2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d348bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.load(\"./model/BPE_model/tokenizer-bpe-conversational-10k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1da412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c970d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"This is a test sentence for the tokenizer.\n",
    "This is a test sentence for the tokenizer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbce2465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test sentence for the tokenizer.\\nThis is a test sentence for the tokenizer.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e88114c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d642153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3014,\n",
       " 1162,\n",
       " 1106,\n",
       " 2512,\n",
       " 2211,\n",
       " 1165,\n",
       " 1117,\n",
       " 1122,\n",
       " 4055,\n",
       " 1294,\n",
       " 1670,\n",
       " 4,\n",
       " 3014,\n",
       " 1162,\n",
       " 1106,\n",
       " 2512,\n",
       " 2211,\n",
       " 1165,\n",
       " 1117,\n",
       " 1122,\n",
       " 4055,\n",
       " 1294,\n",
       " 1670]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(test_text).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc6e9339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This Ġis Ġa Ġtest Ġsentence Ġfor Ġthe Ġto ken iz er. Ċ This Ġis Ġa Ġtest Ġsentence Ġfor Ġthe Ġto ken iz er.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.decode(new_tokenizer.tokenizer.encode(test_text).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba11b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a python program to add two numbers \n",
      "num1 = 1.5\n",
      "num2 = 6.3\n",
      "sum = num1 + num2\n",
      "print(f'Sum: {sum}')\n",
      "\n",
      "\n",
      "# write a python function to add two user provided numbers and return the sum\n",
      "def add_two_numbers(num1, num2):\n",
      "    sum = num1 + num2\n",
      "    return sum\n",
      "\n",
      "\n",
      "# write a program to find and print the largest among three numbers\n",
      "\n",
      "num1 = 10\n",
      "num2 = 12\n",
      "num3 = 14\n",
      "if (num1 >= num2) and (num1 >= num3):\n",
      "   largest = num1\n",
      "elif (num2 >= num1) and (num2 >= num3):\n",
      "   largest = num2\n",
      "else:\n",
      "   largest = num3\n",
      "print(f'largest:{largest}')\n",
      "\n",
      "\n",
      "# write a program to find and print the smallest among three numbers\n",
      "num1 = 10\n",
      "num2 = 12\n",
      "num3 = 14\n",
      "if (num1 <= num2) and (num1 <= num3):\n",
      "   smallest = num1\n",
      "elif (num2 <= num1) and (num2 <= num3):\n",
      "   smallest = num2\n",
      "else:\n",
      "   smallest = num3\n",
      "print(f'smallest:{smallest}')\n",
      "\n",
      "\n",
      "# Write a python function to merge two given lists into one\n",
      "def merge_lists(l1, l2):\n",
      "    return l1 + l2\n",
      "\n",
      "\n",
      "# Write a program to check whether a number is prime or not\n",
      "num = 337\n",
      "\n",
      "if num > 1:\n",
      "   for i in ra\n"
     ]
    }
   ],
   "source": [
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7de45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test sentence for the tokenizer.\n",
      "This is a test sentence for the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "print(new_tokenizer.decode_clean(new_tokenizer.encode(test_text).ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ba03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_tokenizer.tokenizer.add_special_tokens([\"/n\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d85840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġstr:'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.id_to_token(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3459375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " 'Ġ',\n",
       " 'i',\n",
       " 's',\n",
       " 'Ġ',\n",
       " 'a',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'Ġ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " 'Ġ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'o',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " 'i',\n",
       " 'z',\n",
       " 'e',\n",
       " 'r',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'T',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " 'Ġ',\n",
       " 'i',\n",
       " 's',\n",
       " 'Ġ',\n",
       " 'a',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'Ġ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " 'Ġ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'Ġ',\n",
       " 't',\n",
       " 'o',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " 'i',\n",
       " 'z',\n",
       " 'e',\n",
       " 'r',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_tokenizer.tokenizer.encode(test_text).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53dd1bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġtest',\n",
       " 'Ġsentence',\n",
       " 'Ġfor',\n",
       " 'Ġthe',\n",
       " 'Ġtoken',\n",
       " 'izer',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'This',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġtest',\n",
       " 'Ġsentence',\n",
       " 'Ġfor',\n",
       " 'Ġthe',\n",
       " 'Ġtoken',\n",
       " 'izer',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3610ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test sentence for the tokenizer.\\nThis is a test sentence for the tokenizer.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14635594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d9af88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'Ġtest', 'Ċ', 'test']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(\"test test\\ntest\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89ef089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[251, 1940, 4, 251]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(\"test test\\ntest\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d27535fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(\"\\n\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef7e497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ċ'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.decode([4],skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9f583ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test Ġtest Ċ test'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.decode(new_tokenizer.tokenizer.encode(\"test test\\ntest\").ids,skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "79073d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  3231,  6251,  2005,  1996, 19204, 17629,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(test_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c348092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_tokenizer.save_model(\"./data/PythonCodeDataSmall_TextOnly/BPE_data/bpe_modelV1_1024_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8f02ee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test sentence for the tokenizer.'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5b35d1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1161, 155, 68, 208, 524, 144, 140, 2396, 4115, 17, 3, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1] + new_tokenizer.tokenizer.encode(test_text).ids + [3,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "cfca1421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test sentence for the token izer .'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.decode([1] + new_tokenizer.tokenizer.encode(test_text).ids + [3,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6e8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.pre_data = preprocess_data(data)\n",
    "        self.tokens_data = tokenize_data(self.pre_data)['input_ids'].to(dtype=torch.long)\n",
    "        # self.tokens_data_new = new_tokenizer.tokenize(data)\n",
    "        tt = [F.pad(torch.tensor(new_tokenizer.tokenizer.encode(dd).ids, dtype=torch.int), mode='constant', pad=(0, max(128 - len(new_tokenizer.tokenizer.encode(dd).tokens), -10000000)), value=0) for dd in self.pre_data]\n",
    "        self.tokens_data_new = torch.stack(tt)\n",
    "    def __len__(self):\n",
    "        return len(self.tokens_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokens_data[idx], self.tokens_data_new[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9f8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_instance = data_loader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca1ec9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(data_loader_instance, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b871fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnablePositionalEmbedding(Module):\n",
    "    def __init__(self, max_seq_len: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = Embedding(max_seq_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        return x + self.pos_embedding(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6299bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding(Module):\n",
    "    def __init__(self, vocab_size, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.word_embedding1 = Embedding(vocab_size, d_model)\n",
    "        # self.layer_norm1 = torch.nn.LayerNorm(d_model)\n",
    "        # self.word_embedding2 = Linear(vocab_size//2, vocab_size//4)\n",
    "        # self.layer_norm2 = torch.nn.LayerNorm(vocab_size//4)\n",
    "        # self.word_embedding3 = Linear(vocab_size//4, d_model)\n",
    "        # self.layer_norm3 = torch.nn.LayerNorm(d_model)\n",
    "        # self.tanh = torch.nn.Tanh()\n",
    "        self.pos_embedding = LearnablePositionalEmbedding(max_seq_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embedding1(x)\n",
    "        # x = self.layer_norm1(x)\n",
    "        # x = self.word_embedding2(x)\n",
    "        # x = self.layer_norm2(x)\n",
    "        # x = self.word_embedding3(x)\n",
    "        # x = self.layer_norm3(x)\n",
    "        # x = self.tanh(x)\n",
    "        x = self.pos_embedding(x)\n",
    "        # x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ed7458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b76e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class large_embedding(Module):\n",
    "    def __init__(self, vocab_size, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.word_embedding1 = encoding.embeddings.word_embeddings\n",
    "        self.positional_embedding = encoding.embeddings.position_embeddings\n",
    "        # self.layer_norm = encoding.embeddings.LayerNorm\n",
    "        # self.dropout = encoding.embeddings.dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_e = self.word_embedding1(x)\n",
    "        # x = self.layer_norm(x)\n",
    "        # x = self.dropout(x)\n",
    "        x_p = self.positional_embedding(torch.arange(0, x.size(1), device=x.device).unsqueeze(0).expand(x.size(0), -1))\n",
    "        x = x_e + x_p\n",
    "        # x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2700ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0925ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51e79c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "079131a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embedding(\n",
       "  (word_embedding1): Embedding(5120, 768)\n",
       "  (pos_embedding): LearnablePositionalEmbedding(\n",
       "    (pos_embedding): Embedding(128, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = embedding(vocab_size=1024*5, d_model=384*2, max_seq_len=128)\n",
    "embedding_model.train()\n",
    "for layer in embedding_model.parameters():\n",
    "    layer.requires_grad = True\n",
    "\n",
    "# large_embedding_model = large_embedding(vocab_size=1024*5, d_model=384, max_seq_len=128)\n",
    "# large_embedding_model.eval()\n",
    "# for layer in large_embedding_model.parameters():\n",
    "#     layer.requires_grad = False\n",
    "\n",
    "encoding.to(device)\n",
    "embedding_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a03047",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(embedding_model.parameters(), lr=0.001)\n",
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f7b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in encoding.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3674a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [118,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [114,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [121,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [113,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [110,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [126,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m target = encoding(batch)\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m new_batch = \u001b[43mnew_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m output = embedding_model(new_batch)\n\u001b[32m     12\u001b[39m loss = criterion(output, target.last_hidden_state)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_loss = 0\n",
    "for e in range(epoch):\n",
    "    for batch, new_batch in dataset_loader:\n",
    "        batch = batch.to(device)\n",
    "        n_batch = batch.size(0)\n",
    "        max_seq_len = batch.size(1)\n",
    "        target = encoding(batch)\n",
    "        optimizer.zero_grad()\n",
    "        new_batch = new_batch.to(device)\n",
    "        output = embedding_model(new_batch)\n",
    "        loss = criterion(output, target.last_hidden_state)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"Epoch {e}, Batch Loss: {loss.item()}\")\n",
    "        batch_loss += loss.item()\n",
    "    print(f\"Epoch {e}, Loss: {batch_loss / len(dataset_loader)}\")\n",
    "    batch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e66ee4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "68e34a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embedding_model.state_dict(), \"./model/Transformer/embedding_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8bb6d0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 128, 384])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "01decf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 128, 384])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ab9ae1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0287,  0.1369, -0.2417,  0.0326,  0.0839, -0.1499, -0.0455,  0.0542,\n",
       "        -0.3117, -0.3579], device='cuda:0')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.last_hidden_state[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e6f0bbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0639,  0.2435, -0.0936,  0.0264, -0.1986, -0.1604,  0.0187, -0.0192,\n",
       "        -0.2563, -0.1595], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fa475ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del embedding_model\n",
    "del encoding\n",
    "del optimizer\n",
    "del criterion\n",
    "del target\n",
    "del output\n",
    "del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c615c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6741f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512, 384])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b12eb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10,20)) + list(range(0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8505468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/PythonCodeDataSmall_TextOnly/Python_code_data.txt\", \"r\") as f:\n",
    "    data = f.read(-1)\n",
    "    data = data.split(\"\\n# \")\n",
    "    data = [data[0].strip(\"\\n\")] + [(\"# \" + c).strip(\"\\n\") for c in data[1:] if len(c) >= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bff3c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# write a python program to add two numbers \\nnum1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\nprint(f'Sum: {sum}')\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22c46e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tokenizer.tokenizer.encode(data[0]).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3cc91a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 159,\n",
       " 68,\n",
       " 167,\n",
       " 174,\n",
       " 126,\n",
       " 391,\n",
       " 286,\n",
       " 249,\n",
       " 384,\n",
       " 32,\n",
       " 20,\n",
       " 17,\n",
       " 24,\n",
       " 402,\n",
       " 32,\n",
       " 25,\n",
       " 17,\n",
       " 22,\n",
       " 225,\n",
       " 32,\n",
       " 384,\n",
       " 14,\n",
       " 402,\n",
       " 121,\n",
       " 11,\n",
       " 73,\n",
       " 10,\n",
       " 876,\n",
       " 29,\n",
       " 94,\n",
       " 225,\n",
       " 641]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(data[0]).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fb3690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# write a python program to add two numbers num1 = 1 . 5 num2 = 6 . 3 sum = num1 + num2 print ( f ' Sum : { sum }')\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.decode([1] + new_tokenizer.tokenizer.encode(data[0]).ids + [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "75760368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'write',\n",
       " 'a',\n",
       " 'python',\n",
       " 'program',\n",
       " 'to',\n",
       " 'add',\n",
       " 'two',\n",
       " 'numbers',\n",
       " 'num1',\n",
       " '=',\n",
       " '1',\n",
       " '.',\n",
       " '5',\n",
       " 'num2',\n",
       " '=',\n",
       " '6',\n",
       " '.',\n",
       " '3',\n",
       " 'sum',\n",
       " '=',\n",
       " 'num1',\n",
       " '+',\n",
       " 'num2',\n",
       " 'print',\n",
       " '(',\n",
       " 'f',\n",
       " \"'\",\n",
       " 'Sum',\n",
       " ':',\n",
       " '{',\n",
       " 'sum',\n",
       " \"}')\"]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.tokenizer.encode(data[0]).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2d65999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[b for b in range(10)] for a in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f4dcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1925e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*4/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65159c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd732f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\":\"Module\",\"children\":[1,3,5,7,9,11]},{\"type\":\"Expr\",\"children\":[2]},{\"type\":\"Str\",\"value\":\" \n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/PythonSourceCodeData3.79GB/py150/python100k_train.json\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    data = f.read(100)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "with open('./data/PythonSourceCodeData3.79GB/py150/python100k_train.json', 'r') as file:\n",
    "    for index, line in enumerate(file):\n",
    "        json_data_list = json.loads(line)\n",
    "        # print(json_data_list)\n",
    "        # Cache for already processed nodes to avoid redundant work / infinite loops\n",
    "        processed_nodes_cache = {}\n",
    "\n",
    "        def build_ast_node(node_index, all_nodes):\n",
    "            \"\"\"\n",
    "            Recursively builds a standard Python AST node from the custom JSON format.\n",
    "            Needs to be implemented thoroughly based on the JSON structure's rules.\n",
    "            \"\"\"\n",
    "            if node_index in processed_nodes_cache:\n",
    "                return processed_nodes_cache[node_index]\n",
    "\n",
    "            if node_index >= len(all_nodes):\n",
    "                raise IndexError(f\"Node index {node_index} is out of bounds (total nodes: {len(all_nodes)})\")\n",
    "\n",
    "            node_data = all_nodes[node_index]\n",
    "            node_type = node_data.get('type')\n",
    "            children_indices = node_data.get('children', [])\n",
    "            value = node_data.get('value') # Can be None\n",
    "\n",
    "            # Helper to get processed child nodes\n",
    "            def get_children():\n",
    "                return [build_ast_node(child_idx, all_nodes) for child_idx in children_indices]\n",
    "\n",
    "            # --- === CORE MAPPING LOGIC === ---\n",
    "            # This is where you translate *your* JSON types to standard `ast` objects.\n",
    "            # This requires careful analysis of your JSON format.\n",
    "            # Below are EXAMPLES for a few types - YOU MUST COMPLETE THIS.\n",
    "\n",
    "            ast_node = None # Initialize\n",
    "\n",
    "            if node_type == 'Module':\n",
    "                # A Module contains a list of statements in its body\n",
    "                body_stmts = get_children()\n",
    "                ast_node = ast.Module(body=body_stmts, type_ignores=[])\n",
    "\n",
    "            elif node_type == 'Expr':\n",
    "                # An expression statement contains a single value (which is an expression node)\n",
    "                if len(children_indices) != 1:\n",
    "                    raise ValueError(f\"Expr node {node_index} should have 1 child, got {len(children_indices)}\")\n",
    "                expr_value = build_ast_node(children_indices[0], all_nodes)\n",
    "                ast_node = ast.Expr(value=expr_value)\n",
    "\n",
    "            elif node_type == 'Str':\n",
    "                # Represents a string constant\n",
    "                ast_node = ast.Constant(value=str(value)) # Use ast.Constant for Py 3.8+\n",
    "\n",
    "            elif node_type == 'Num':\n",
    "                # Represents a number constant (int or float)\n",
    "                ast_node = ast.Constant(value=value) # ast.Constant handles int/float\n",
    "\n",
    "            elif node_type == 'NameLoad':\n",
    "                # Represents loading a variable's value\n",
    "                if not isinstance(value, str):\n",
    "                    raise ValueError(f\"NameLoad node {node_index} needs a string 'value', got {type(value)}\")\n",
    "                ast_node = ast.Name(id=value, ctx=ast.Load())\n",
    "\n",
    "            elif node_type == 'NameStore':\n",
    "                # Represents assigning to a variable\n",
    "                if not isinstance(value, str):\n",
    "                    raise ValueError(f\"NameStore node {node_index} needs a string 'value', got {type(value)}\")\n",
    "                ast_node = ast.Name(id=value, ctx=ast.Store())\n",
    "\n",
    "            elif node_type == 'ImportFrom':\n",
    "                # Represents 'from module import name1, name2 ...'\n",
    "                module_name = value\n",
    "                alias_nodes = get_children() # Children should be 'alias' type nodes\n",
    "                # Filter out potential non-alias nodes if structure is inconsistent\n",
    "                valid_aliases = [n for n in alias_nodes if isinstance(n, ast.alias)]\n",
    "                if len(valid_aliases) != len(alias_nodes):\n",
    "                    print(f\"Warning: ImportFrom node {node_index} children were not all alias nodes.\")\n",
    "                ast_node = ast.ImportFrom(module=module_name, names=valid_aliases, level=0) # Assuming level=0\n",
    "\n",
    "            elif node_type == 'Import':\n",
    "                # Represents 'import module1, module2 ...'\n",
    "                alias_nodes = get_children() # Children should be 'alias' type nodes\n",
    "                valid_aliases = [n for n in alias_nodes if isinstance(n, ast.alias)]\n",
    "                if len(valid_aliases) != len(alias_nodes):\n",
    "                    print(f\"Warning: Import node {node_index} children were not all alias nodes.\")\n",
    "                ast_node = ast.Import(names=valid_aliases)\n",
    "\n",
    "            elif node_type == 'alias':\n",
    "                # Represents an imported name, possibly with an 'as' rename\n",
    "                name = value\n",
    "                asname = node_data.get('asname') # Check if your JSON includes 'asname'\n",
    "                # Handle 'from x import *' case\n",
    "                if name == '*':\n",
    "                    # Special handling: ast.ImportFrom uses names=[ast.alias(name='*', asname=None)]\n",
    "                    name = '*'\n",
    "                    asname = None\n",
    "                elif not isinstance(name, str):\n",
    "                    raise ValueError(f\"alias node {node_index} needs a string 'value', got {type(name)}\")\n",
    "\n",
    "                ast_node = ast.alias(name=name, asname=asname) # asname can be None\n",
    "\n",
    "            elif node_type == 'Assign':\n",
    "                # Represents assignment, e.g., x = y or x, z = y\n",
    "                # ASSUMPTION: First child is target(s), second is value\n",
    "                if len(children_indices) != 2:\n",
    "                    raise ValueError(f\"Assign node {node_index} expects 2 children (targets, value), got {len(children_indices)}\")\n",
    "                targets_node = build_ast_node(children_indices[0], all_nodes)\n",
    "                value_node = build_ast_node(children_indices[1], all_nodes)\n",
    "\n",
    "                # Ensure targets is a list for ast.Assign\n",
    "                targets_list = []\n",
    "                if isinstance(targets_node, (ast.Tuple, ast.List)):\n",
    "                    # Handle multiple assignment targets like x, y = ...\n",
    "                    targets_list = targets_node.elts\n",
    "                else:\n",
    "                    targets_list = [targets_node]\n",
    "\n",
    "                ast_node = ast.Assign(targets=targets_list, value=value_node)\n",
    "\n",
    "            elif node_type == 'ListLoad':\n",
    "                # Represents a list literal being used/loaded\n",
    "                elements = get_children()\n",
    "                ast_node = ast.List(elts=elements, ctx=ast.Load())\n",
    "\n",
    "            elif node_type == 'TupleLoad':\n",
    "                # Represents a tuple literal being used/loaded\n",
    "                elements = get_children()\n",
    "                ast_node = ast.Tuple(elts=elements, ctx=ast.Load())\n",
    "\n",
    "            # --- TODO: Add MANY MORE ELIF BLOCKS ---\n",
    "            # You need to handle:\n",
    "            # - FunctionDef, ClassDef (with arguments, body, decorators, bases)\n",
    "            # - Call (function calls with args, kwargs)\n",
    "            # - AttributeLoad, AttributeStore (e.g., obj.attr)\n",
    "            # - SubscriptLoad, SubscriptStore (e.g., list[index])\n",
    "            # - If, For, While, TryExcept, With (control flow)\n",
    "            # - Return, Raise, Break, Continue\n",
    "            # - Binary operations (BinOpAdd, BinOpSub, etc.)\n",
    "            # - Comparisons (CompareEq, CompareLt, etc.)\n",
    "            # - Boolean ops (BoolOpAnd, BoolOpOr)\n",
    "            # - Unary ops (UnaryOpNot, UnaryOpInvert)\n",
    "            # - DictLoad, SetLoad\n",
    "            # - Comprehensions (ListComp, DictComp, SetComp, GeneratorExp)\n",
    "            # - Lambda\n",
    "            # - arguments, arg (for function definitions)\n",
    "            # - ... and potentially others based on your specific code.\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: Unhandled node type '{node_type}' at index {node_index}. Data: {node_data}\")\n",
    "                # Return a placeholder or raise an error\n",
    "                # Returning a simple Constant placeholder for now\n",
    "                ast_node = ast.Constant(value=f\"UNHANDLED<{node_type}>\")\n",
    "                # raise NotImplementedError(f\"AST building not implemented for type: {node_type}\")\n",
    "\n",
    "            if ast_node is None:\n",
    "                raise ValueError(f\"Failed to create AST node for index {node_index} with type {node_type}\")\n",
    "\n",
    "            # Cache the result before returning\n",
    "            processed_nodes_cache[node_index] = ast_node\n",
    "            return ast_node\n",
    "\n",
    "        # --- Main Execution ---\n",
    "        try:\n",
    "            print(\"Building AST from JSON data...\")\n",
    "            # Start building from the root node (assuming it's index 0 and type 'Module')\n",
    "            root_node = build_ast_node(0, json_data_list)\n",
    "\n",
    "            # Perform some basic validation\n",
    "            if not isinstance(root_node, ast.Module):\n",
    "                print(f\"Error: Root node (index 0) was not converted to an ast.Module. Got: {type(root_node)}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            print(\"AST construction finished (may have warnings for unhandled types).\")\n",
    "\n",
    "            # Add line numbers and column offsets (optional but good practice)\n",
    "            print(\"Fixing missing AST locations...\")\n",
    "            ast.fix_missing_locations(root_node)\n",
    "\n",
    "            print(\"Unparsing AST to Python code...\")\n",
    "            # Convert the reconstructed AST back to Python code\n",
    "            python_code = unparse(root_node)\n",
    "\n",
    "            print(\"\\n--- Generated Python Code ---\")\n",
    "            print(python_code)\n",
    "            print(\"-----------------------------\\n\")\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(f\"\\nError: An index was out of bounds. This often means a 'children' list points\")\n",
    "            print(f\"       to a node that doesn't exist in the main list.\")\n",
    "            print(f\"       Details: {e}\")\n",
    "        except (ValueError, TypeError, NotImplementedError) as e:\n",
    "            print(f\"\\nError during AST construction or mapping:\")\n",
    "            print(f\"       Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn unexpected error occurred:\")\n",
    "            print(f\"       Details: {e}\")\n",
    "            import traceback\n",
    "            print(\"\\nTraceback:\")\n",
    "            traceback.print_exc()\n",
    "        if index == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "import json # If your input is a JSON string/file\n",
    "\n",
    "# --- Choose the appropriate unparser ---\n",
    "if sys.version_info >= (3, 9):\n",
    "    from ast import unparse\n",
    "    print(\"Using built-in ast.unparse (Python 3.9+)\")\n",
    "else:\n",
    "    try:\n",
    "        from astunparse import unparse\n",
    "        print(\"Using 'astunparse' library.\")\n",
    "    except ImportError:\n",
    "        print(\"\\nError: This script requires Python 3.9+ for ast.unparse \")\n",
    "        print(\"or the 'astunparse' library for older Python versions.\")\n",
    "        print(\"Please install it: pip install astunparse\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# --- Your JSON data ---\n",
    "# (Using the first JSON list you provided as an example)\n",
    "json_data_list = [\n",
    "    {'type': 'Module', 'children': [1, 3, 5, 7, 9, 11]},\n",
    "    {'type': 'Expr', 'children': [2]},\n",
    "    {'type': 'Str', 'value': ' Provides ``mapping`` of url paths to request handlers.\\n'},\n",
    "    {'type': 'ImportFrom', 'children': [4], 'value': 'bootstrap'},\n",
    "    {'type': 'alias', 'value': 'Bootstrap'},\n",
    "    {'type': 'ImportFrom', 'children': [6], 'value': 'fund'},\n",
    "    {'type': 'alias', 'value': 'InstantPaymentNotificationHandler'},\n",
    "    {'type': 'ImportFrom', 'children': [8], 'value': 'fund'},\n",
    "    {'type': 'alias', 'value': 'ThankYouHandler'},\n",
    "    {'type': 'ImportFrom', 'children': [10], 'value': 'view'},\n",
    "    {'type': 'alias', 'value': '*'}, # Represents 'from view import *'\n",
    "    {'type': 'Assign', 'children': [12, 13]},\n",
    "    {'type': 'NameStore', 'value': 'mapping'},\n",
    "    {'type': 'ListLoad', 'children': [14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 71, 74, 77, 80, 83, 86, 89, 92, 95, 98, 101, 104, 107, 110, 113]},\n",
    "    {'type': 'TupleLoad', 'children': [15, 16]},\n",
    "    {'type': 'Str', 'value': '/'},\n",
    "    {'type': 'NameLoad', 'value': 'Index'},\n",
    "    {'type': 'TupleLoad', 'children': [18, 19]},\n",
    "    {'type': 'Str', 'value': '/ipn'},\n",
    "    {'type': 'NameLoad', 'value': 'InstantPaymentNotificationHandler'},\n",
    "    {'type': 'TupleLoad', 'children': [21, 22]},\n",
    "    {'type': 'Str', 'value': '/thank-you'},\n",
    "    {'type': 'NameLoad', 'value': 'ThankYouHandler'},\n",
    "    {'type': 'TupleLoad', 'children': [24, 25]},\n",
    "    {'type': 'Str', 'value': '/about\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'About'},\n",
    "    {'type': 'TupleLoad', 'children': [27, 28]},\n",
    "    {'type': 'Str', 'value': '/guide\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Guide'},\n",
    "    {'type': 'TupleLoad', 'children': [30, 31]},\n",
    "    {'type': 'Str', 'value': '/guide/download\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Download'},\n",
    "    {'type': 'TupleLoad', 'children': [33, 34]},\n",
    "    {'type': 'Str', 'value': '/guide/standards\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Standards'},\n",
    "    {'type': 'TupleLoad', 'children': [36, 37]},\n",
    "    {'type': 'Str', 'value': '/community\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Community'},\n",
    "    {'type': 'TupleLoad', 'children': [39, 40]},\n",
    "    {'type': 'Str', 'value': '/news\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'News'},\n",
    "    {'type': 'TupleLoad', 'children': [42, 43]},\n",
    "    {'type': 'Str', 'value': '/support\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Support'},\n",
    "    {'type': 'TupleLoad', 'children': [45, 46]},\n",
    "    {'type': 'Str', 'value': '/contact\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Contact'},\n",
    "    {'type': 'TupleLoad', 'children': [48, 49]},\n",
    "    {'type': 'Str', 'value': '/press\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Press'},\n",
    "    {'type': 'TupleLoad', 'children': [51, 52]},\n",
    "    {'type': 'Str', 'value': '/legal/terms'},\n",
    "    {'type': 'NameLoad', 'value': 'Terms'},\n",
    "    {'type': 'TupleLoad', 'children': [54, 55]},\n",
    "    {'type': 'Str', 'value': '/library\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Library'},\n",
    "    {'type': 'TupleLoad', 'children': [57, 58]},\n",
    "    {'type': 'Str', 'value': '/library/sketchup\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Library'},\n",
    "    {'type': 'TupleLoad', 'children': [60, 61]},\n",
    "    {'type': 'Str', 'value': '/library/series/(\\\\w+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Library'},\n",
    "    {'type': 'TupleLoad', 'children': [63, 64]},\n",
    "    {'type': 'Str', 'value': '/library/users\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Users'},\n",
    "    {'type': 'TupleLoad', 'children': [66, 67]},\n",
    "    {'type': 'Str', 'value': '/library/users/([0-9]+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'User'},\n",
    "    {'type': 'TupleLoad', 'children': [69, 70]},\n",
    "    {'type': 'Str', 'value': '/library/designs/([0-9]+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Design'},\n",
    "    {'type': 'TupleLoad', 'children': [72, 73]},\n",
    "    {'type': 'Str', 'value': '/library/designs/([0-9]+)/(edit)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Design'},\n",
    "    {'type': 'TupleLoad', 'children': [75, 76]},\n",
    "    {'type': 'Str', 'value': '/library/designs\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Design'},\n",
    "    {'type': 'TupleLoad', 'children': [78, 79]},\n",
    "    {'type': 'Str', 'value': '/library/designs/add\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Design'},\n",
    "    {'type': 'TupleLoad', 'children': [81, 82]},\n",
    "    {'type': 'Str', 'value': '/library/designs/add/sketchup\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Design'},\n",
    "    {'type': 'TupleLoad', 'children': [84, 85]},\n",
    "    {'type': 'Str', 'value': '/redirect/success/([0-9]+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'RedirectSuccess'},\n",
    "    {'type': 'TupleLoad', 'children': [87, 88]},\n",
    "    {'type': 'Str', 'value': '/redirect/error\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'RedirectError'},\n",
    "    {'type': 'TupleLoad', 'children': [90, 91]},\n",
    "    {'type': 'Str', 'value': '/redirect/after/delete\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'RedirectAfterDelete'},\n",
    "    {'type': 'TupleLoad', 'children': [93, 94]},\n",
    "    {'type': 'Str', 'value': '/admin/moderate\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Moderate'},\n",
    "    {'type': 'TupleLoad', 'children': [96, 97]},\n",
    "    {'type': 'Str', 'value': '/admin/bootstrap\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Bootstrap'},\n",
    "    {'type': 'TupleLoad', 'children': [99, 100]},\n",
    "    {'type': 'Str', 'value': '/activity'},\n",
    "    {'type': 'NameLoad', 'value': 'ActivityScreen'},\n",
    "    {'type': 'TupleLoad', 'children': [102, 103]},\n",
    "    {'type': 'Str', 'value': '/txns'},\n",
    "    {'type': 'NameLoad', 'value': 'TxnList'},\n",
    "    {'type': 'TupleLoad', 'children': [105, 106]},\n",
    "    {'type': 'Str', 'value': '/blob64/([^/]+)/([^/]+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Base64Blob'},\n",
    "    {'type': 'TupleLoad', 'children': [108, 109]},\n",
    "    {'type': 'Str', 'value': '/blob64/([^/]+)\\\\/?'},\n",
    "    {'type': 'NameLoad', 'value': 'Base64Blob'},\n",
    "    {'type': 'TupleLoad', 'children': [111, 112]},\n",
    "    {'type': 'Str', 'value': '/i18n/message_strings.json'},\n",
    "    {'type': 'NameLoad', 'value': 'MessageStrings'},\n",
    "    {'type': 'TupleLoad', 'children': [114, 115]},\n",
    "    {'type': 'Str', 'value': '/.*'},\n",
    "    {'type': 'NameLoad', 'value': 'NotFound'}\n",
    "]\n",
    "# You would repeat this for the second JSON list if needed\n",
    "\n",
    "# --- AST Reconstruction Logic ---\n",
    "\n",
    "# Cache for already processed nodes to avoid redundant work / infinite loops\n",
    "processed_nodes_cache = {}\n",
    "\n",
    "def build_ast_node(node_index, all_nodes):\n",
    "    \"\"\"\n",
    "    Recursively builds a standard Python AST node from the custom JSON format.\n",
    "    Needs to be implemented thoroughly based on the JSON structure's rules.\n",
    "    \"\"\"\n",
    "    if node_index in processed_nodes_cache:\n",
    "        return processed_nodes_cache[node_index]\n",
    "\n",
    "    if node_index >= len(all_nodes):\n",
    "        raise IndexError(f\"Node index {node_index} is out of bounds (total nodes: {len(all_nodes)})\")\n",
    "\n",
    "    node_data = all_nodes[node_index]\n",
    "    node_type = node_data.get('type')\n",
    "    children_indices = node_data.get('children', [])\n",
    "    value = node_data.get('value') # Can be None\n",
    "\n",
    "    # Helper to get processed child nodes\n",
    "    def get_children():\n",
    "        return [build_ast_node(child_idx, all_nodes) for child_idx in children_indices]\n",
    "\n",
    "    # --- === CORE MAPPING LOGIC === ---\n",
    "    # This is where you translate *your* JSON types to standard `ast` objects.\n",
    "    # This requires careful analysis of your JSON format.\n",
    "    # Below are EXAMPLES for a few types - YOU MUST COMPLETE THIS.\n",
    "\n",
    "    ast_node = None # Initialize\n",
    "\n",
    "    if node_type == 'Module':\n",
    "        # A Module contains a list of statements in its body\n",
    "        body_stmts = get_children()\n",
    "        ast_node = ast.Module(body=body_stmts, type_ignores=[])\n",
    "\n",
    "    elif node_type == 'Expr':\n",
    "        # An expression statement contains a single value (which is an expression node)\n",
    "        if len(children_indices) != 1:\n",
    "            raise ValueError(f\"Expr node {node_index} should have 1 child, got {len(children_indices)}\")\n",
    "        expr_value = build_ast_node(children_indices[0], all_nodes)\n",
    "        ast_node = ast.Expr(value=expr_value)\n",
    "\n",
    "    elif node_type == 'Str':\n",
    "        # Represents a string constant\n",
    "        ast_node = ast.Constant(value=str(value)) # Use ast.Constant for Py 3.8+\n",
    "\n",
    "    elif node_type == 'Num':\n",
    "        # Represents a number constant (int or float)\n",
    "         ast_node = ast.Constant(value=value) # ast.Constant handles int/float\n",
    "\n",
    "    elif node_type == 'NameLoad':\n",
    "        # Represents loading a variable's value\n",
    "        if not isinstance(value, str):\n",
    "             raise ValueError(f\"NameLoad node {node_index} needs a string 'value', got {type(value)}\")\n",
    "        ast_node = ast.Name(id=value, ctx=ast.Load())\n",
    "\n",
    "    elif node_type == 'NameStore':\n",
    "        # Represents assigning to a variable\n",
    "        if not isinstance(value, str):\n",
    "             raise ValueError(f\"NameStore node {node_index} needs a string 'value', got {type(value)}\")\n",
    "        ast_node = ast.Name(id=value, ctx=ast.Store())\n",
    "\n",
    "    elif node_type == 'ImportFrom':\n",
    "        # Represents 'from module import name1, name2 ...'\n",
    "        module_name = value\n",
    "        alias_nodes = get_children() # Children should be 'alias' type nodes\n",
    "        # Filter out potential non-alias nodes if structure is inconsistent\n",
    "        valid_aliases = [n for n in alias_nodes if isinstance(n, ast.alias)]\n",
    "        if len(valid_aliases) != len(alias_nodes):\n",
    "             print(f\"Warning: ImportFrom node {node_index} children were not all alias nodes.\")\n",
    "        ast_node = ast.ImportFrom(module=module_name, names=valid_aliases, level=0) # Assuming level=0\n",
    "\n",
    "    elif node_type == 'Import':\n",
    "         # Represents 'import module1, module2 ...'\n",
    "         alias_nodes = get_children() # Children should be 'alias' type nodes\n",
    "         valid_aliases = [n for n in alias_nodes if isinstance(n, ast.alias)]\n",
    "         if len(valid_aliases) != len(alias_nodes):\n",
    "             print(f\"Warning: Import node {node_index} children were not all alias nodes.\")\n",
    "         ast_node = ast.Import(names=valid_aliases)\n",
    "\n",
    "    elif node_type == 'alias':\n",
    "        # Represents an imported name, possibly with an 'as' rename\n",
    "        name = value\n",
    "        asname = node_data.get('asname') # Check if your JSON includes 'asname'\n",
    "        # Handle 'from x import *' case\n",
    "        if name == '*':\n",
    "             # Special handling: ast.ImportFrom uses names=[ast.alias(name='*', asname=None)]\n",
    "             name = '*'\n",
    "             asname = None\n",
    "        elif not isinstance(name, str):\n",
    "             raise ValueError(f\"alias node {node_index} needs a string 'value', got {type(name)}\")\n",
    "\n",
    "        ast_node = ast.alias(name=name, asname=asname) # asname can be None\n",
    "\n",
    "    elif node_type == 'Assign':\n",
    "        # Represents assignment, e.g., x = y or x, z = y\n",
    "        # ASSUMPTION: First child is target(s), second is value\n",
    "        if len(children_indices) != 2:\n",
    "            raise ValueError(f\"Assign node {node_index} expects 2 children (targets, value), got {len(children_indices)}\")\n",
    "        targets_node = build_ast_node(children_indices[0], all_nodes)\n",
    "        value_node = build_ast_node(children_indices[1], all_nodes)\n",
    "\n",
    "        # Ensure targets is a list for ast.Assign\n",
    "        targets_list = []\n",
    "        if isinstance(targets_node, (ast.Tuple, ast.List)):\n",
    "             # Handle multiple assignment targets like x, y = ...\n",
    "             targets_list = targets_node.elts\n",
    "        else:\n",
    "             targets_list = [targets_node]\n",
    "\n",
    "        ast_node = ast.Assign(targets=targets_list, value=value_node)\n",
    "\n",
    "    elif node_type == 'ListLoad':\n",
    "         # Represents a list literal being used/loaded\n",
    "         elements = get_children()\n",
    "         ast_node = ast.List(elts=elements, ctx=ast.Load())\n",
    "\n",
    "    elif node_type == 'TupleLoad':\n",
    "         # Represents a tuple literal being used/loaded\n",
    "         elements = get_children()\n",
    "         ast_node = ast.Tuple(elts=elements, ctx=ast.Load())\n",
    "\n",
    "    # --- TODO: Add MANY MORE ELIF BLOCKS ---\n",
    "    # You need to handle:\n",
    "    # - FunctionDef, ClassDef (with arguments, body, decorators, bases)\n",
    "    # - Call (function calls with args, kwargs)\n",
    "    # - AttributeLoad, AttributeStore (e.g., obj.attr)\n",
    "    # - SubscriptLoad, SubscriptStore (e.g., list[index])\n",
    "    # - If, For, While, TryExcept, With (control flow)\n",
    "    # - Return, Raise, Break, Continue\n",
    "    # - Binary operations (BinOpAdd, BinOpSub, etc.)\n",
    "    # - Comparisons (CompareEq, CompareLt, etc.)\n",
    "    # - Boolean ops (BoolOpAnd, BoolOpOr)\n",
    "    # - Unary ops (UnaryOpNot, UnaryOpInvert)\n",
    "    # - DictLoad, SetLoad\n",
    "    # - Comprehensions (ListComp, DictComp, SetComp, GeneratorExp)\n",
    "    # - Lambda\n",
    "    # - arguments, arg (for function definitions)\n",
    "    # - ... and potentially others based on your specific code.\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Unhandled node type '{node_type}' at index {node_index}. Data: {node_data}\")\n",
    "        # Return a placeholder or raise an error\n",
    "        # Returning a simple Constant placeholder for now\n",
    "        ast_node = ast.Constant(value=f\"UNHANDLED<{node_type}>\")\n",
    "        # raise NotImplementedError(f\"AST building not implemented for type: {node_type}\")\n",
    "\n",
    "    if ast_node is None:\n",
    "         raise ValueError(f\"Failed to create AST node for index {node_index} with type {node_type}\")\n",
    "\n",
    "    # Cache the result before returning\n",
    "    processed_nodes_cache[node_index] = ast_node\n",
    "    return ast_node\n",
    "\n",
    "# --- Main Execution ---\n",
    "try:\n",
    "    print(\"Building AST from JSON data...\")\n",
    "    # Start building from the root node (assuming it's index 0 and type 'Module')\n",
    "    root_node = build_ast_node(0, json_data_list)\n",
    "\n",
    "    # Perform some basic validation\n",
    "    if not isinstance(root_node, ast.Module):\n",
    "        print(f\"Error: Root node (index 0) was not converted to an ast.Module. Got: {type(root_node)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"AST construction finished (may have warnings for unhandled types).\")\n",
    "\n",
    "    # Add line numbers and column offsets (optional but good practice)\n",
    "    print(\"Fixing missing AST locations...\")\n",
    "    ast.fix_missing_locations(root_node)\n",
    "\n",
    "    print(\"Unparsing AST to Python code...\")\n",
    "    # Convert the reconstructed AST back to Python code\n",
    "    python_code = unparse(root_node)\n",
    "\n",
    "    print(\"\\n--- Generated Python Code ---\")\n",
    "    print(python_code)\n",
    "    print(\"-----------------------------\\n\")\n",
    "\n",
    "except IndexError as e:\n",
    "    print(f\"\\nError: An index was out of bounds. This often means a 'children' list points\")\n",
    "    print(f\"       to a node that doesn't exist in the main list.\")\n",
    "    print(f\"       Details: {e}\")\n",
    "except (ValueError, TypeError, NotImplementedError) as e:\n",
    "    print(f\"\\nError during AST construction or mapping:\")\n",
    "    print(f\"       Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred:\")\n",
    "    print(f\"       Details: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nTraceback:\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
